{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0301438-d9c2-4b66-a194-39cd2c3caedf",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# 3D Temperature Diffusion Model: Bringing it all together\n",
    "\n",
    "------- The goal for this section is to provide the simple easy version, and then get them to do the NumPy and CuPy versions. The goal of the temperature diffusion to give the basic example and do two thing, make scaling plots for particular function and implement NumPy and CuPy version and then do the same profiling for them -----\n",
    "\n",
    "----- The analysis that i have conducted can still be included but this should be for my RTX 3070 rather than on the HPC and then for them to use that to compare to what they have. \n",
    "\n",
    "To highlight the difference between NumPy and CuPy, a 3D temperature diffusion model is used to highlight the difference in performance that can be achieved for computationally intensive tasks. \n",
    "\n",
    "# Data \n",
    "\n",
    "For this task, starting data of 3-dimensional Ocean Temperatures are required, which we can download from the [Copernicus Marine Data Service](https://data.marine.copernicus.eu/product/GLOBAL_ANALYSISFORECAST_PHY_001_024/description). \n",
    "\n",
    "## Downloading Data \n",
    "\n",
    "A utility function has been included with the repo for this course bundled with poetry, as explained in the [README](../README.md). \n",
    "\n",
    "``` bash \n",
    "poetry run download_data\n",
    "```\n",
    "\n",
    "will download the required dataset for this course into nthe `./data` directory. The dataset that is downloaded is: \n",
    "\n",
    "**Description**:  \n",
    "This dataset was downloaded from the **Global Ocean Physics Analysis and Forecast** service. It provides data for global ocean physics, focusing on sea water potential temperature.\n",
    "\n",
    "- **Product Identifier**: `GLOBAL_ANALYSISFORECAST_PHY_001_024`\n",
    "- **Product Name**: Global Ocean Physics Analysis and Forecast\n",
    "- **Dataset Identifier**: `cmems_mod_glo_phy-thetao_anfc_0.083deg_PT6H-i`\n",
    "\n",
    "**Variable Visualized**:  \n",
    "- **Sea Water Potential Temperature (thetao)**: Measured in degrees Celsius [°C].\n",
    "\n",
    "**Geographical Area of Interest**:  \n",
    "- **Region**: Around the United Kingdom\n",
    "- **Coordinates**:\n",
    "  - **Northern Latitude**: 65.312\n",
    "  - **Eastern Longitude**: 6.1860\n",
    "  - **Southern Latitude**: 46.829\n",
    "  - **Western Longitude**: -13.90\n",
    "\n",
    "**Depth Range**:  \n",
    "- **Minimum Depth**: 0.49 meters  \n",
    "- **Maximum Depth**: 5727.9 meters\n",
    "\n",
    "**File Size**:  \n",
    "- **267.5 MB**\n",
    "\n",
    "## Visualising Data \n",
    "\n",
    "To make the process of visualising the data easier, three different utility functions have been created. The defeault output locations for the visualisations is within the `output` directory.\n",
    "\n",
    "### Visualise Slice (Static) \n",
    "\n",
    "Visualizing a 2D temperature slice. The depth that will be targetted is the surface, e.g. 0.49m.\n",
    "\n",
    "``` bash \n",
    "poetry run visualise_slice_static\n",
    "```\n",
    "\n",
    "The output producded will be a `.png` file, such as: \n",
    "\n",
    "![Temperature Slice](../_static/temperature_slice_static.png)\n",
    "\n",
    "\n",
    "### Visualise Slice - Interactive HTML file\n",
    "\n",
    "Visualizing a 2D temperature slice in an interactive HTML file, allowing for a time series to be visualised. \n",
    "\n",
    "``` bash \n",
    "poetry run visualise_slice --target_depth 0 --animation_speed 100\n",
    "```\n",
    "\n",
    "The command above will create an interactive HTML file, that will have each timestep in the animation last for 100 milliseconds (`--animation_speed`) at the nearest depth to the closest depth (`--target_depth`), in this case 0.49m. For the above command the output producded will be: \n",
    "\n",
    "<iframe\n",
    "  src=\"../_static/temperature_slice.html\"\n",
    "  width=\"800\"\n",
    "  height=\"600\"\n",
    "  frameborder=\"0\"\n",
    "  allowfullscreen\n",
    "></iframe>\n",
    "\n",
    "When run within your own space the file produced will be `output/original_temperature_2d_interactive.html`.\n",
    "\n",
    "### Visualise Cube - Interactive HTML file\n",
    "\n",
    "Visualizing a 3D temperature slice in an interactive HTML file, allowing for a time series to be visualised. \n",
    "\n",
    "``` bash \n",
    "poetry run visualise_cube --num_depths 5 --num_time_steps 3\n",
    "```\n",
    "\n",
    "The command above will create an interactive HTML file, that will visualise the first 5 depth, for 3 time steps. For the above command the output producded will be: \n",
    "\n",
    "<iframe\n",
    "  src=\"../_static/temperature_cube.html\"\n",
    "  width=\"800\"\n",
    "  height=\"600\"\n",
    "  frameborder=\"0\"\n",
    "  allowfullscreen\n",
    "></iframe>\n",
    "\n",
    "When run within your own space the file produced will be `output/original_temperature_3d_interactive.html`.\n",
    "\n",
    "## Summarising Data \n",
    "\n",
    "Calculates and prints summary statistics for temperature data in a specified NetCDF file. Prints its mean, max, min, and standard deviation. Also provides information about the dataset’s dimensions and coordinates.\n",
    "\n",
    "``` bash \n",
    "poetry run summary\n",
    "```\n",
    "\n",
    "\n",
    "The above command will print out the summary of the data on the original datafile downloaded from Copernicus. The above command will output the following: \n",
    "\n",
    "``` \n",
    "The dimensions of the data is: (5, 50, 222, 241)\n",
    "Temperature Summary Statistics:\n",
    "Mean temperature: 8.56154727935791\n",
    "Max temperature: 14.050389289855957\n",
    "Min temperature: -2.591400146484375\n",
    "Standard deviation: 3.1273183822631836\n",
    "\n",
    "Dataset Dimensions and Coordinates:\n",
    "<xarray.Dataset>\n",
    "Dimensions:    (depth: 50, latitude: 222, longitude: 241, time: 5)\n",
    "Coordinates:\n",
    "  * depth      (depth) float32 0.494 1.541 2.646 ... 5.275e+03 5.728e+03\n",
    "  * latitude   (latitude) float32 46.83 46.92 47.0 47.08 ... 65.08 65.17 65.25\n",
    "  * longitude  (longitude) float32 -13.83 -13.75 -13.67 ... 6.0 6.083 6.167\n",
    "  * time       (time) datetime64[ns] 2024-01-01 ... 2024-01-02\n",
    "Data variables:\n",
    "    thetao     (time, depth, latitude, longitude) float32 13.47 13.42 ... nan\n",
    "Attributes: (12/14)\n",
    "    Conventions:                   CF-1.6\n",
    "    area:                          GLOBAL\n",
    "    contact:                       servicedesk.cmems@mercator-ocean.eu\n",
    "    credit:                        E.U. Copernicus Marine Service Information...\n",
    "    institution:                   Mercator Ocean\n",
    "    licence:                       http://marine.copernicus.eu/services-portf...\n",
    "    ...                            ...\n",
    "    product_user_manual:           http://marine.copernicus.eu/documents/PUM/...\n",
    "    quality_information_document:  http://marine.copernicus.eu/documents/QUID...\n",
    "    references:                    http://marine.copernicus.eu\n",
    "    source:                        MERCATOR GLO12\n",
    "    title:                         Instantaneous fields for product GLOBAL_AN...\n",
    "    copernicusmarine_version:      1.3.4\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d5fd14-4f2c-4206-983a-8e7922f4ed88",
   "metadata": {},
   "source": [
    "# Leaveaging GPUs\n",
    "\n",
    "## Pseudocode\n",
    "\n",
    "The psuedocode that implements the diffusion loop is: \n",
    "\n",
    "```\n",
    "1. For each timestep from 1 to num_timesteps:\n",
    "   2. Copy the current temperature values to a temporary array (temp_copy)\n",
    "   3. Initialize arrays for neighbor sums and neighbor counts with zeros\n",
    "   4. For each valid cell (ignoring boundaries):\n",
    "      5. Calculate the sum of neighboring cells:\n",
    "         - Add the value of the front neighbor if valid\n",
    "         - Add the value of the back neighbor if valid\n",
    "         - Add the value of the left neighbor if valid\n",
    "         - Add the value of the right neighbor if valid\n",
    "         - Add the value of the top neighbor if valid\n",
    "         - Add the value of the bottom neighbor if valid\n",
    "      6. Count the number of valid neighbors for each direction\n",
    "   7. Update the cell's temperature:\n",
    "      - New temperature = current temperature + diffusion coefficient * (neighbor_sum - 6 * current temperature) / neighbor_count\n",
    "   8. Ensure invalid points (NaN) remain unchanged\n",
    "   9. Update the main temperature array with the new values\n",
    "```\n",
    "\n",
    "## Running with NumPy \n",
    "\n",
    "``` bash \n",
    "poetry run diffusion_numpy --num_timesteps 100\n",
    "```\n",
    "\n",
    "The above command will run the 3D diffusion model using the NumPy version of the code for 100 timesteps. Once the execution has finished then a report will be provided concerning the time taken for execution. When running on an AMD EPYC 7552 48-Core Processor, the execution outputs:\n",
    "\n",
    "```  \n",
    "NumPy model completed in 489.2647 seconds. Average time per timestep: 4.8926 seconds.\n",
    "```\n",
    "\n",
    "You can visualise the model outputs producded with \n",
    "\n",
    "``` bash \n",
    "poetry run visualise_slice --target_depth 0 --animation_speed 100 --data_file predicted_temperatures_numpy.nc \n",
    "```\n",
    "\n",
    "Of note is that the file `predicted_temperatures_numpy.nc` is generated during the execution of the above command for the script `diffusion_numpy`. This will then generate a new interactive HTML file `output/predicted_temperature_2d_interactive.html`.\n",
    "\n",
    "\n",
    "## Running With CuPy\n",
    "\n",
    "As the same code has been wrote in CuPy you can experiment with the difference between CPU and GPU code with the following:\n",
    "\n",
    "``` bash \n",
    "poetry run diffusion_cupy --num_timesteps 100\n",
    "```\n",
    "\n",
    "The above command will run the 3D diffusion model using the CuPy version of the code for 100 timesteps. Once the execution has finished then a report will be provided concerning the time taken for execution. When running on an NVIDIA A40 GPU, the execution outputs:\n",
    "\n",
    "``` \n",
    "CuPy model completed in 171.9884 seconds. Average time per timestep: 1.7199 seconds.\n",
    "```\n",
    "\n",
    "You can visualise the model outputs producded with \n",
    "\n",
    "``` bash \n",
    "poetry run visualise_slice --target_depth 0 --animation_speed 100 --data_file predicted_temperatures_cupy.nc \n",
    "```\n",
    "\n",
    "Of note is that the file `predicted_temperatures_numpy.nc` is generated during the execution of the above command for the script `diffusion_numpy`. This will then generate a new interactive HTML file `output/predicted_temperature_2d_interactive.html`.\n",
    "\n",
    "## Performance Comparison: CPU vs GPU\n",
    "\n",
    "### Overall Speedup\n",
    "- **CPU runtime**: 489 seconds  \n",
    "- **GPU runtime**: 171.9884 seconds  \n",
    "- **Speedup factor**:  \n",
    "  \\[\n",
    "  \\text{Speedup} = \\frac{\\text{CPU time}}{\\text{GPU time}} = \\frac{489}{171.9884} \\approx 2.84\n",
    "  \\]  \n",
    "  The GPU completed the task approximately 2.84 times faster than the CPU.\n",
    "\n",
    "### Per-Timestep Speedup\n",
    "- **CPU average timestep**: 4.9 seconds  \n",
    "- **GPU average timestep**: 1.7199 seconds  \n",
    "- **Speedup factor per timestep**:  \n",
    "  \\[\n",
    "  \\text{Speedup per timestep} = \\frac{\\text{CPU timestep}}{\\text{GPU timestep}} = \\frac{4.9}{1.7199} \\approx 2.85\n",
    "  \\]  \n",
    "  On a per-timestep basis, the GPU is about 2.85 times faster.\n",
    "\n",
    "### Efficiency Observation\n",
    "- The consistent speedup factor (both overall and per timestep) suggests that the GPU effectively parallelizes computations without significant overhead from data transfer or kernel launches.\n",
    "\n",
    "### Implications\n",
    "- **Computational Efficiency**:  \n",
    "  Using a GPU provides substantial performance gains, especially for tasks with repetitive, parallelizable computations such as numerical modeling or simulations.\n",
    "- **Observed Speedup** (~2.84x improvement) suggests:  \n",
    "  - The task is well-suited for GPU acceleration.  \n",
    "  - Full potential of the GPU might not yet be realized due to:\n",
    "    - Limited parallelism in the workload.  \n",
    "    - Overheads from memory transfers between CPU and GPU.  \n",
    "    - Suboptimal use of GPU-specific optimizations.\n",
    "\n",
    "The GPU's performance significantly outpaces the CPU for this task, reducing runtime by approximately 65%. Of note is that this approach is simply a direct move from NumPy to CuPy which represents a minimal amount of effort. Further optimization of the GPU code could enhance performance and exploit its full potential, leveraging on known time intensive tasks for GPUs such as data transfer. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336dff9f-060f-4109-87ba-753e1b8f0760",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
